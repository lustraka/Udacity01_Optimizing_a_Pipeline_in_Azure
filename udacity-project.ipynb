{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-147342\n",
            "Azure region: southcentralus\n",
            "Subscription id: 976ee174-3882-4721-b90a-b5fef6b72f24\n",
            "Resource group: aml-quickstarts-147342\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1623924794930
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create compute cluster\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"cpucluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)\n",
        "\n",
        "# Create a custom environment that encapsulates the training script's dependencies\n",
        "# (1) Define your conda dependencies in a YAML file\n",
        "# (2) Create an Azure ML environment from this Conda environment specification."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating.........\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1623924848668
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\r\n",
        "\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- pip=20.2.4\r\n",
        "- pip:\r\n",
        "    - azureml-defaults\r\n",
        "    - scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing conda_dependencies.yml\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "\r\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623925184064
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "# from azureml.train.sklearn import SKLearn >> DEPRECATED. Use the ScriptRunConfig object with your own defined environment.\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling(\n",
        "    {\n",
        "    'C': uniform(0.001, 1.0), # For regularization\n",
        "    'max_iter': choice(10, 50, 100) # Max number of epochs\n",
        "    }\n",
        ")\n",
        "\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "# DEPRECATED. Create a SKLearn estimator for use with train.py > Instead:\n",
        "# Create a ScriptRunConfig object to specify the configuration details of your training job\n",
        "\n",
        "est = ScriptRunConfig(source_directory='.',\n",
        "                      script='train.py',\n",
        "                      compute_target=cpu_cluster,\n",
        "                      environment=sklearn_env)\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(estimator=est,\n",
        "                                    hyperparameter_sampling=ps,\n",
        "                                    policy=policy,\n",
        "                                    primary_metric_name='Accuracy',\n",
        "                                    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                    max_total_runs=20,\n",
        "                                    max_concurrent_runs=4,\n",
        "                                    max_duration_minutes=30)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1623925317496
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(ScriptRunConfig)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class ScriptRunConfig in module azureml.core.script_run_config:\n",
            "\n",
            "class ScriptRunConfig(azureml._logging.chained_identity.ChainedIdentity)\n",
            " |  Represents configuration information for submitting a training run in Azure Machine Learning.\n",
            " |  \n",
            " |  A ScriptRunConfig packages together the configuration information needed to submit a run in Azure ML, including\n",
            " |  the script, compute target, environment, and any distributed job-specific configs.\n",
            " |  \n",
            " |  Once a script run is configured and submitted with the :meth:`azureml.core.Experiment.submit`,\n",
            " |  a :class:`azureml.core.script_run.ScriptRun` is returned.\n",
            " |  \n",
            " |  .. remarks::\n",
            " |  \n",
            " |      The Azure Machine Learning SDK provides you with a series of interconnected classes, that are\n",
            " |      designed to help you train and compare machine learning models that are related by the shared\n",
            " |      problem that they are solving.\n",
            " |  \n",
            " |      An :class:`azureml.core.Experiment` acts as a logical container for these training runs. A ScriptRunConfig\n",
            " |      object is used to configure the information necessary for submitting a training run as part of an Experiment.\n",
            " |      When a run is submitted using a ScriptRunConfig object, the submit method returns an object of type\n",
            " |      :class:`azureml.core.ScriptRun`. Then returned ScriptRun object gives you programmatic access to information\n",
            " |      about the training run. ScriptRun is a child class of :class:`azureml.core.Run`.\n",
            " |  \n",
            " |      The key concept to remember is that there are different configuration objects that are used to\n",
            " |      submit an experiment, based on what kind of run you want to trigger. The type of the configuration object\n",
            " |      then informs what child class of Run you get back from the submit method. When you pass a\n",
            " |      ScriptRunConfig object in a call to Experiment's submit method, you get back a ScriptRun object.\n",
            " |      Examples of other run objects returned include :class:`azureml.train.automl.run.AutoMLRun` (returned for\n",
            " |      an AutoML run) and :class:`azureml.pipeline.core.PipelineRun` (returned for a Pipeline run).\n",
            " |  \n",
            " |      The following sample shows how to submit a training script on your local machine.\n",
            " |  \n",
            " |      .. code-block:: python\n",
            " |  \n",
            " |              from azureml.core import ScriptRunConfig, Experiment\n",
            " |  \n",
            " |              # create or load an experiment\n",
            " |              experiment = Experiment(workspace, 'MyExperiment')\n",
            " |              # create or retrieve a compute target\n",
            " |              cluster = workspace.compute_targets['MyCluster']\n",
            " |              # create or retrieve an environment\n",
            " |              env = Environment.get(ws, name='MyEnvironment')\n",
            " |              # configure and submit your training run\n",
            " |              config = ScriptRunConfig(source_directory='.',\n",
            " |                                       script='train.py',\n",
            " |                                       arguments=['--arg1', arg1_val, '--arg2', arg2_val],\n",
            " |                                       compute_target=cluster,\n",
            " |                                       environment=env)\n",
            " |              script_run = experiment.submit(config)\n",
            " |  \n",
            " |      The following example shows how to submit a training script on your cluster using the command property\n",
            " |      instead of script and arguments.\n",
            " |  \n",
            " |      .. code-block:: python\n",
            " |  \n",
            " |              from azureml.core import ScriptRunConfig, Experiment\n",
            " |              # create or load an experiment\n",
            " |              experiment = Experiment(workspace, 'MyExperiment')\n",
            " |              # create or retrieve a compute target\n",
            " |              cluster = workspace.compute_targets['MyCluster']\n",
            " |              # create or retrieve an environment\n",
            " |              env = Environment.get(ws, name='MyEnvironment')\n",
            " |              # configure and submit your training run\n",
            " |              config = ScriptRunConfig(source_directory='.',\n",
            " |                                       command=['python', 'train.py', '--arg1', arg1_val],\n",
            " |                                       compute_target=cluster,\n",
            " |                                       environment=env)\n",
            " |              script_run = experiment.submit(config)\n",
            " |  \n",
            " |      The following sample shows how to run a command on your cluster.\n",
            " |  \n",
            " |      .. code-block:: python\n",
            " |  \n",
            " |              from azureml.core import ScriptRunConfig, Experiment\n",
            " |              # create or load an experiment\n",
            " |              experiment = Experiment(workspace, 'MyExperiment')\n",
            " |              # create or retrieve a compute target\n",
            " |              cluster = workspace.compute_targets['MyCluster']\n",
            " |              # create or retrieve an environment\n",
            " |              env = Environment.get(ws, name='MyEnvironment')\n",
            " |              # configure and submit your training run\n",
            " |              config = ScriptRunConfig(source_directory='.',\n",
            " |                                       command=['ls', '-l'],\n",
            " |                                       compute_target=cluster,\n",
            " |                                       environment=env)\n",
            " |              script_run = experiment.submit(config)\n",
            " |  \n",
            " |      For more examples showing how to work with ScriptRunConfig, see:\n",
            " |  \n",
            " |      * the article `Select and use a compute target to train your\n",
            " |        model <https://docs.microsoft.com/azure/machine-learning/how-to-set-up-training-targets>`_\n",
            " |      * these `training\n",
            " |        notebooks <https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/training>`_\n",
            " |  \n",
            " |  :param source_directory: A local directory containing code files needed for a run.\n",
            " |  :type source_directory: str\n",
            " |  :param script: The file path relative to the source_directory of the script to be run.\n",
            " |  :type script: str\n",
            " |  :param arguments: Optional command line arguments to pass to the training script.\n",
            " |      Arguments are passed in pairs, for example, ['--arg1', arg1_val, '--arg2', arg2_val].\n",
            " |  :type arguments: builtin.list or str\n",
            " |  :param run_config: Optional run configuration to use.\n",
            " |  :type run_config: azureml.core.runconfig.RunConfiguration\n",
            " |  :param _telemetry_values: Internal use only.\n",
            " |  :type _telemetry_values: dict\n",
            " |  :param compute_target: The compute target where training will happen. This can either be a ComputeTarget\n",
            " |      object, the name of an existing ComputeTarget, or the string \"local\". If no compute target is\n",
            " |      specified, your local machine will be used.\n",
            " |  :type compute_target: azureml.core.compute_target.AbstractComputeTarget or str\n",
            " |  :param environment: The environment to use for the run. If no environment is specified,\n",
            " |      azureml.core.runconfig.DEFAULT_CPU_IMAGE will be used as the Docker image for the run.\n",
            " |  :type environment: azureml.core.environment.Environment\n",
            " |  :param distributed_job_config: For jobs that require additional distributed job-specific configurations.\n",
            " |  :type distributed_job_config: azureml.core.runconfig.TensorflowConfiguration,\n",
            " |      azureml.core.runconfig.MpiConfiguration, or azureml.core.runconfig.PyTorchConfiguration\n",
            " |  :param resume_from: The DataPath containing the checkpoint or model files from which to resume the\n",
            " |      experiment.\n",
            " |  :type resume_from: azureml.data.datapath.DataPath\n",
            " |  :param max_run_duration_seconds: The maximum time allowed for the run. The system will attempt to\n",
            " |      automatically cancel the run if it took longer than this value.\n",
            " |      :type max_run_duration_seconds: int\n",
            " |  :param command: The command to be submitted for the run. The command property can also be used instead of\n",
            " |      script/arguments. Both command and script/argument properties cannot be used together to submit a run.\n",
            " |      To submit a script file using the command property - ['python', 'train.py', '--arg1', arg1_val]\n",
            " |      To run an actual command - ['ls']\n",
            " |  :type command: builtin.list[str] or str\n",
            " |  :param docker_runtime_config: For jobs that require Docker runtime-specific configurations.\n",
            " |  :type docker_runtime_config: azureml.core.runconfig.DockerConfiguration\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      ScriptRunConfig\n",
            " |      azureml._logging.chained_identity.ChainedIdentity\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, source_directory, script=None, arguments=None, run_config=None, _telemetry_values=None, compute_target=None, environment=None, distributed_job_config=None, resume_from=None, max_run_duration_seconds=2592000, command=None, docker_runtime_config=None)\n",
            " |      Class ScriptRunConfig constructor.\n",
            " |      \n",
            " |      :param source_directory: A local directory containing code files needed for a run.\n",
            " |      :type source_directory: str\n",
            " |      :param script: The file path relative to the source_directory of the script to be run.\n",
            " |      :type script: str\n",
            " |      :param arguments: Optional command line arguments to pass to the training script.\n",
            " |          Arguments are passed in pairs, for example, ['--arg1', arg1_val, '--arg2', arg2_val].\n",
            " |      :type arguments: builtin.list[str]\n",
            " |      :param run_config: Optional run configuration to use.\n",
            " |      :type run_config: azureml.core.runconfig.RunConfiguration\n",
            " |      :param _telemetry_values: Internal use only.\n",
            " |      :type _telemetry_values: dict\n",
            " |      :param compute_target: The compute target where training will happen. This can either be a ComputeTarget\n",
            " |          object, the name of an existing ComputeTarget, or the string \"local\". If no compute target is\n",
            " |          specified, your local machine will be used.\n",
            " |      :type compute_target: azureml.core.compute_target.AbstractComputeTarget or str\n",
            " |      :param environment: The environment to use for the run. If no environment is specified,\n",
            " |          azureml.core.runconfig.DEFAULT_CPU_IMAGE will be used as the Docker image for the run.\n",
            " |      :type environment: azureml.core.environment.Environment\n",
            " |      :param distributed_job_config: For jobs that require additional distributed job-specific configurations.\n",
            " |      :type distributed_job_config: azureml.core.runconfig.TensorflowConfiguration,\n",
            " |          azureml.core.runconfig.MpiConfiguration, or azureml.core.runconfig.PyTorchConfiguration\n",
            " |      :param resume_from: The DataPath containing the checkpoint or model files from which to resume the\n",
            " |          experiment.\n",
            " |      :type resume_from: azureml.data.datapath.DataPath\n",
            " |      :param max_run_duration_seconds: The maximum time allowed for the run. The system will attempt to\n",
            " |          automatically cancel the run if it took longer than this value.\n",
            " |      :type max_run_duration_seconds: int\n",
            " |      :param command: The command to be submitted for the run. The command property can also be used instead of\n",
            " |          script/arguments. Both command and script/argument properties cannot be used together to submit a run.\n",
            " |          To submit a script file using the command property - ['python', 'train.py', '--arg1', arg1_val]\n",
            " |          To run an actual command - ['ls']\n",
            " |      :type command: builtin.list[str] or str\n",
            " |      :param docker_runtime_config: For jobs that require Docker runtime-specific configurations.\n",
            " |      :type docker_runtime_config: azureml.core.runconfig.DockerConfiguration\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  MAX_DURATION_SECONDS_DEFAULT = 2592000\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from azureml._logging.chained_identity.ChainedIdentity:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  identity\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from azureml._logging.chained_identity.ChainedIdentity:\n",
            " |  \n",
            " |  DELIM = '#'\n",
            "\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623925788690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "hdr = exp.submit(config=hyperdrive_config)\n",
        "RunDetails(hdr).show()\n",
        "hdr.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ScriptRunConfig' object has no attribute '_compute_target'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ecc6ed4247bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Submit your hyperdrive run to the experiment and show run details with the widget.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/hyperdrive/_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(hyperdrive_config, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperdrive_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ScriptRunConfig' object has no attribute '_compute_target'"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598276310862
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(### YOUR DATA OBJECT HERE ###)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275726969
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=,\n",
        "    primary_metric=,\n",
        "    training_data=,\n",
        "    label_column_name=,\n",
        "    n_cross_validations=)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598275665403
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete() is used to deprovision and delete the AmlCompute target. \r\n",
        "\r\n",
        "cpu_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}